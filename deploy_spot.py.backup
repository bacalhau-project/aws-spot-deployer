#!/usr/bin/env uv run -s
# /// script
# requires-python = ">=3.11"
# dependencies = [
#     "boto3",
#     "pyyaml",
#     "rich",
# ]
# ///
"""
AWS Spot Instance Deployer - Single File Version

A simple tool for deploying and managing AWS spot instances with beautiful Rich output.
Focused on simplicity and maintainability over enterprise features.

Usage:
    ./deploy_spot.py setup     # Setup environment
    ./deploy_spot.py create    # Deploy spot instances
    ./deploy_spot.py list      # List running instances
    ./deploy_spot.py destroy   # Terminate instances and cleanup resources
    ./deploy_spot.py --help    # Show help

Features:
    - Enhanced console logging with instance ID and IP address context
    - Log messages show: [i-1234567890abcdef0 @ 54.123.45.67] SUCCESS: Created
    - Makes it easy to identify which instance is producing each log message

Single file with all functionality included.
"""

import base64
import json
import logging
import os
import random
import subprocess
import sys
import tarfile
import threading
import time
from concurrent.futures import ThreadPoolExecutor
from datetime import datetime
from typing import Dict, List, Optional

import boto3
import yaml

# Global caches for AWS resources to speed up deployment
VPC_CACHE = {}
SUBNET_CACHE = {}
SECURITY_GROUP_CACHE = {}
AMI_CACHE = {}
CACHE_LOCK = threading.Lock()

try:
    from rich.console import Console
    from rich.layout import Layout
    from rich.live import Live
    from rich.panel import Panel
    from rich.progress import (
        BarColumn,
        Progress,
        SpinnerColumn,
        TaskProgressColumn,
        TextColumn,
        TimeElapsedColumn,
    )
    from rich.table import Table

    RICH_AVAILABLE = True
except ImportError:
    RICH_AVAILABLE = False

console = Console() if RICH_AVAILABLE else None

# =============================================================================
# UI CONSTANTS
# =============================================================================


class ColumnWidths:
    """Defines the widths for the Rich status table columns."""

    REGION = 20
    INSTANCE_ID = 22
    STATUS = 35
    TYPE = 12
    PUBLIC_IP = 18
    CREATED = 28  # Increased to fit ISO 8601 time
    PADDING = 7  # for borders and spacing

    @classmethod
    def get_total_width(cls):
        return sum(
            [
                cls.REGION,
                cls.INSTANCE_ID,
                cls.STATUS,
                cls.TYPE,
                cls.PUBLIC_IP,
                cls.CREATED,
                cls.PADDING,
            ]
        )


# =============================================================================
# RICH OUTPUT HELPERS
# =============================================================================


def rich_print(text: str, style: str = None) -> None:
    """Print with Rich styling if available, fallback to regular print."""
    if RICH_AVAILABLE and console:
        console.print(text, style=style)
    else:
        print(text)


def rich_status(text: str) -> None:
    """Print status message with Rich styling."""
    if RICH_AVAILABLE and console:
        console.print(f"[bold blue]INFO: {text}[/bold blue]")
    else:
        print(f"INFO: {text}")


def rich_success(text: str) -> None:
    """Print success message with Rich styling."""
    if RICH_AVAILABLE and console:
        console.print(f"[bold green]SUCCESS: {text}[/bold green]")
    else:
        print(f"SUCCESS: {text}")


def rich_error(text: str) -> None:
    """Print error message with Rich styling."""
    if RICH_AVAILABLE and console:
        console.print(f"[bold red]ERROR: {text}[/bold red]")
    else:
        print(f"ERROR: {text}")


def rich_warning(text: str) -> None:
    """Print warning message with Rich styling."""
    if RICH_AVAILABLE and console:
        console.print(f"[bold yellow]WARN: {text}[/bold yellow]")
    else:
        print(f"WARN: {text}")


# =============================================================================
# CONFIGURATION
# =============================================================================


class SimpleConfig:
    """Enhanced configuration loader with full options support."""

    def __init__(self, config_file: str = "config.yaml"):
        self.config_file = config_file
        self.data = self._load_config()

    def _load_config(self) -> Dict:
        """Load YAML configuration."""
        try:
            with open(self.config_file, "r") as f:
                return yaml.safe_load(f) or {}
        except FileNotFoundError:
            print(f"Config file {self.config_file} not found. Run 'setup' first.")
            return {}
        except Exception as e:
            print(f"Error loading config: {e}")
            return {}

    def regions(self) -> List[str]:
        """Get list of regions."""
        return [list(region.keys())[0] for region in self.data.get("regions", [])]

    def instance_count(self) -> int:
        """Get total instance count."""
        return self.data.get("aws", {}).get("total_instances", 3)

    def username(self) -> str:
        """Get SSH username."""
        return self.data.get("aws", {}).get("username", "ubuntu")

    def ssh_key_name(self) -> Optional[str]:
        """Get SSH key name if configured."""
        return self.data.get("aws", {}).get("ssh_key_name")

    def public_ssh_key_path(self) -> Optional[str]:
        """Get public SSH key file path."""
        return self.data.get("aws", {}).get("public_ssh_key_path")

    def private_ssh_key_path(self) -> Optional[str]:
        """Get private SSH key file path."""
        return self.data.get("aws", {}).get("private_ssh_key_path")

    def public_ssh_key_content(self) -> Optional[str]:
        """Get public SSH key content."""
        key_path = self.public_ssh_key_path()
        if key_path and os.path.exists(key_path):
            try:
                with open(key_path, "r") as f:
                    return f.read().strip()
            except Exception as e:
                print(f"Error reading public key: {e}")
        return None

    def files_directory(self) -> str:
        """Get files directory path."""
        return self.data.get("aws", {}).get("files_directory", "files")

    def scripts_directory(self) -> str:
        """Get scripts directory path."""
        return self.data.get("aws", {}).get("scripts_directory", "instance/scripts")

    def cloud_init_template(self) -> str:
        """Get cloud-init template path."""
        return self.data.get("aws", {}).get(
            "cloud_init_template", "instance/cloud-init/init-vm-template.yml"
        )

    def startup_script(self) -> str:
        """Get startup script path."""
        return self.data.get("aws", {}).get(
            "startup_script", "instance/scripts/startup.py"
        )

    def additional_commands_script(self) -> Optional[str]:
        """Get additional commands script path."""
        return self.data.get("aws", {}).get("additional_commands_script")

    def bacalhau_data_dir(self) -> str:
        """Get Bacalhau data directory."""
        return self.data.get("aws", {}).get("bacalhau_data_dir", "/bacalhau_data")

    def bacalhau_node_dir(self) -> str:
        """Get Bacalhau node directory."""
        return self.data.get("aws", {}).get("bacalhau_node_dir", "/bacalhau_node")

    def bacalhau_config_template(self) -> str:
        """Get Bacalhau config template path."""
        return self.data.get("aws", {}).get(
            "bacalhau_config_template", "instance/config/config-template.yaml"
        )

    def docker_compose_template(self) -> str:
        """Get Docker Compose template path."""
        return self.data.get("aws", {}).get(
            "docker_compose_template", "instance/scripts/docker-compose.yaml"
        )

    def spot_price_limit(self) -> Optional[float]:
        """Get spot price limit."""
        return self.data.get("aws", {}).get("spot_price_limit")

    def instance_storage_gb(self) -> int:
        """Get instance storage size in GB."""
        return self.data.get("aws", {}).get("instance_storage_gb", 20)

    def security_groups(self) -> List[str]:
        """Get additional security groups."""
        return self.data.get("aws", {}).get("security_groups", [])

    def iam_instance_profile(self) -> Optional[str]:
        """Get IAM instance profile if configured."""
        return self.data.get("aws", {}).get("iam_instance_profile")

    def vpc_id(self) -> Optional[str]:
        """Get specific VPC ID."""
        return self.data.get("aws", {}).get("vpc_id")

    def subnet_id(self) -> Optional[str]:
        """Get specific subnet ID."""
        return self.data.get("aws", {}).get("subnet_id")

    def associate_public_ip(self) -> bool:
        """Check if instances should have public IP."""
        return self.data.get("aws", {}).get("associate_public_ip", True)

    def tags(self) -> Dict[str, str]:
        """Get additional tags for instances."""
        return self.data.get("aws", {}).get("tags", {})

    def region_config(self, region: str) -> Dict:
        """Get config for specific region."""
        for r in self.data.get("regions", []):
            if region in r:
                return r[region]
        return {"machine_type": "t3.medium", "image": "auto"}


# =============================================================================
# SIMPLE CACHE UTILITIES
# =============================================================================


def cache_file_fresh(filepath: str, max_age_hours: int = 24) -> bool:
    """Check if cache file is fresh."""
    if not os.path.exists(filepath):
        return False
    age_hours = (time.time() - os.path.getmtime(filepath)) / 3600
    return age_hours < max_age_hours


def load_cache(filepath: str) -> Optional[Dict]:
    """Load data from cache file."""
    if cache_file_fresh(filepath):
        try:
            with open(filepath, "r") as f:
                return json.load(f)
        except Exception:
            pass
    return None


def save_cache(filepath: str, data: Dict) -> None:
    """Save data to cache file."""
    try:
        os.makedirs(os.path.dirname(filepath), exist_ok=True)
        with open(filepath, "w") as f:
            json.dump(data, f, indent=2, default=str)
    except Exception:
        pass


# =============================================================================
# SIMPLE STATE MANAGEMENT
# =============================================================================


class SimpleStateManager:
    """Simple JSON-based state management - replaces SQLite complexity."""

    def __init__(self, state_file: str = "instances.json"):
        self.state_file = state_file

    def load_instances(self) -> List[Dict]:
        """Load instances from JSON file."""
        try:
            with open(self.state_file, "r") as f:
                data = json.load(f)
                return data.get("instances", [])
        except FileNotFoundError:
            return []
        except Exception as e:
            print(f"Error loading state: {e}")
            return []

    def save_instances(self, instances: List[Dict]) -> None:
        """Save instances to JSON file."""
        try:
            data = {"instances": instances, "last_updated": datetime.now().isoformat()}
            with open(self.state_file, "w") as f:
                json.dump(data, f, indent=2, default=str)
        except Exception as e:
            print(f"Error saving state: {e}")

    def add_instance(self, instance: Dict) -> None:
        """Add instance to state."""
        instances = self.load_instances()
        instances.append(instance)
        self.save_instances(instances)

    def remove_instances_by_region(self, region: str) -> int:
        """Remove instances from specific region."""
        instances = self.load_instances()
        original_count = len(instances)
        instances = [i for i in instances if i.get("region") != region]
        self.save_instances(instances)
        return original_count - len(instances)


# =============================================================================
# AWS UTILITIES
# =============================================================================


def get_latest_ubuntu_ami(region: str, log_function=None) -> Optional[str]:
    """Get latest Ubuntu 22.04 LTS AMI for region."""
    cache_file = f".aws_cache/ami_{region}.json"

    def log_message(msg: str):
        if log_function:
            log_function(msg)
        else:
            print(msg)
    
    # Check memory cache first (fastest)
    with CACHE_LOCK:
        if region in AMI_CACHE:
            log_message(f"Using memory-cached AMI for {region}: {AMI_CACHE[region]}")
            return AMI_CACHE[region]

    # Try file cache second
    cached = load_cache(cache_file)
    if cached and "ami_id" in cached:
        log_message(f"Using file-cached AMI for {region}: {cached['ami_id']}")
        # Also store in memory cache
        with CACHE_LOCK:
            AMI_CACHE[region] = cached["ami_id"]
        return cached["ami_id"]

    # Fetch from AWS
    try:
        log_message(f"Fetching AMI for {region}...")
        ec2 = boto3.client("ec2", region_name=region)
        response = ec2.describe_images(
            Owners=["099720109477"],  # Canonical
            Filters=[
                {
                    "Name": "name",
                    "Values": [
                        "ubuntu/images/hvm-ssd/ubuntu-jammy-22.04-amd64-server-*"
                    ],
                },
                {"Name": "state", "Values": ["available"]},
            ],
            # Remove MaxResults - it seems to cause issues
        )

        log_message(
            f"AMI response for {region}: {len(response.get('Images', []))} images found"
        )

        if response["Images"]:
            # Sort by creation date to get latest
            images = sorted(
                response["Images"], key=lambda x: x["CreationDate"], reverse=True
            )
            ami_id = images[0]["ImageId"]
            log_message(f"Found AMI for {region}: {ami_id}")
            # Cache result
            save_cache(
                cache_file, {"ami_id": ami_id, "timestamp": datetime.now().isoformat()}
            )
            return ami_id
        else:
            log_message(f"No Ubuntu AMIs found for {region}")
    except Exception as e:
        log_message(f"Error getting AMI for {region}: {e}")

    return None


def check_aws_auth() -> bool:
    """Quick AWS authentication check."""
    try:
        sts = boto3.client("sts")
        sts.get_caller_identity()
        return True
    except Exception as e:
        if "token has expired" in str(e).lower():
            rich_error("AWS credentials expired. Run: aws sso login")
        else:
            rich_error(f"AWS authentication failed: {e}")
        return False


# =============================================================================
# CONSOLE LOGGER FOR THREAD OUTPUT
# =============================================================================


class ConsoleLogger(logging.Handler):
    """Custom logging handler that adds instance context to console output."""
    
    def __init__(self, console_obj=None, instance_ip_map=None):
        super().__init__()
        self.console = console_obj or console
        self.instance_ip_map = instance_ip_map or {}
        self.setLevel(logging.INFO)
        
    def emit(self, record):
        try:
            msg = self.format(record)
            
            # Check if the message already contains instance ID and IP (like "[i-12345 @ 1.2.3.4] SUCCESS: Created")
            import re
            instance_pattern = re.match(r'^\[([i-][a-z0-9]+)\s*@\s*([\d.]+)\]\s*(.*)', msg)
            
            if instance_pattern:
                # Message already has instance ID and IP, use as-is
                pass  # The message is already formatted correctly
            else:
                # Extract instance key from thread name if available
                thread_name = record.threadName
                instance_key = None
                instance_ip = None
                
                # Thread names are like "Setup-i-1234567890abcdef0" or "Region-us-west-2"
                if thread_name.startswith("Setup-"):
                    instance_key = thread_name.replace("Setup-", "")
                    # Look up IP address from our map
                    instance_ip = self.instance_ip_map.get(instance_key, "")
                elif "-" in thread_name and thread_name.split("-")[0] == "Region":
                    # For region threads, try to extract from the message
                    if "[" in msg and "]" in msg:
                        # Message already has instance key
                        # Try to extract it to look up IP
                        match = re.search(r'\[([^\]]+)\]', msg)
                        if match:
                            potential_key = match.group(1)
                            if potential_key in self.instance_ip_map:
                                instance_key = potential_key
                                instance_ip = self.instance_ip_map.get(potential_key, "")
                    else:
                        # Add region context
                        region = thread_name.replace("Region-", "")
                        msg = f"[{region}] {msg}"
                
                # Build the prefix with instance key and IP
                prefix = ""
                if instance_key:
                    if instance_ip:
                        prefix = f"[{instance_key} @ {instance_ip}]"
                    else:
                        prefix = f"[{instance_key}]"
                    
                    # Only add prefix if it's not already in the message
                    if not msg.startswith(prefix) and not msg.startswith(f"[{instance_key}"):
                        msg = f"{prefix} {msg}"
            
            # Only print SUCCESS and ERROR messages to console
            if "SUCCESS:" in msg or "ERROR:" in msg:
                # Print with appropriate styling
                if "SUCCESS:" in msg:
                    if self.console and RICH_AVAILABLE:
                        self.console.print(f"[bold green]{msg}[/bold green]")
                    else:
                        print(msg)
                elif "ERROR:" in msg:
                    if self.console and RICH_AVAILABLE:
                        self.console.print(f"[bold red]{msg}[/bold red]")
                    else:
                        print(msg)
                        
        except Exception:
            self.handleError(record)


# =============================================================================
# REAL-TIME PROGRESS TRACKING
# =============================================================================


class ProgressTracker:
    """Enhanced progress tracking with Rich progress bars and detailed status updates."""

    def __init__(self):
        self.console = console if RICH_AVAILABLE else None
        self.progress_bars = {}
        self.overall_progress = None
        self.tasks = {}

    def create_overall_progress(self, total_instances: int):
        """Create overall progress bar for all instances."""
        if not RICH_AVAILABLE:
            return

        self.overall_progress = Progress(
            SpinnerColumn(),
            TextColumn("[bold blue]{task.description}"),
            BarColumn(complete_style="green", finished_style="green"),
            TaskProgressColumn(),
            TimeElapsedColumn(),
            console=self.console,
            transient=True,
        )

        overall_task = self.overall_progress.add_task(
            f"Deploying {total_instances} instances",
            total=total_instances * 6,  # 6 phases per instance
        )

        return overall_task

    def create_instance_progress(self, instance_key: str, description: str):
        """Create individual progress bar for a specific instance."""
        if not RICH_AVAILABLE:
            return

        if instance_key not in self.progress_bars:
            self.progress_bars[instance_key] = Progress(
                SpinnerColumn(),
                TextColumn("[bold cyan]{task.description}"),
                BarColumn(complete_style="blue", finished_style="green"),
                TaskProgressColumn(),
                TimeElapsedColumn(),
                console=self.console,
                transient=True,
            )

        task = self.progress_bars[instance_key].add_task(description, total=100)
        self.tasks[instance_key] = task
        return task

    def update_instance_progress(
        self, instance_key: str, phase: str, progress: int, status: str = ""
    ):
        """Update progress for a specific instance phase."""
        if not RICH_AVAILABLE or instance_key not in self.tasks:
            return

        self.progress_bars[instance_key].update(
            self.tasks[instance_key],
            description=f"{phase}: {status}",
            completed=progress,
        )

    def complete_instance_progress(self, instance_key: str, success: bool = True):
        """Mark instance progress as complete."""
        if not RICH_AVAILABLE or instance_key not in self.tasks:
            return

        status = "âœ… Complete" if success else "âŒ Failed"
        self.progress_bars[instance_key].update(
            self.tasks[instance_key], description=status, completed=100
        )


# =============================================================================
# FILE AND SCRIPT HANDLING
# =============================================================================


def generate_minimal_cloud_init(config: SimpleConfig) -> str:
    """Generate minimal cloud-init script for basic setup only."""
    # Get public SSH key content
    public_key = config.public_ssh_key_content()
    if not public_key:
        rich_warning("No public SSH key found - SSH access may not work")
        public_key = ""

    # Create minimal cloud-init script
    cloud_init_script = f"""#cloud-config

users:
  - name: {config.username()}
    sudo: ALL=(ALL) NOPASSWD:ALL
    shell: /bin/bash
    ssh_authorized_keys:
      - {public_key}
    groups: docker

package_update: true
package_upgrade: true

packages:
  - curl
  - wget
  - unzip
  - git
  - python3
  - python3-pip
  - ca-certificates
  - gnupg
  - lsb-release

runcmd:
  - echo "Package updates starting" > /tmp/cloud-init-status
  - echo "[$(date)] Cloud-init starting" >> /var/log/startup-progress.log
  
  # Create directories for uploaded files immediately
  - mkdir -p /opt/uploaded_files/scripts /opt/uploaded_files/config
  - mkdir -p /tmp/uploaded_files/scripts /tmp/uploaded_files/config
  - mkdir -p /tmp/exs  # Temporary location for service files
  - chown -R {config.username()}:{config.username()} /opt/uploaded_files
  - chown -R {config.username()}:{config.username()} /tmp/uploaded_files
  - chown -R {config.username()}:{config.username()} /tmp/exs
  - chmod -R 755 /opt/uploaded_files /tmp/uploaded_files /tmp/exs
  - echo "Upload directories created" > /tmp/cloud-init-status
  
  # Create startup log with proper permissions
  - touch /opt/startup.log
  - chown {config.username()}:{config.username()} /opt/startup.log
  - chmod 666 /opt/startup.log
  
  # Install Docker from official repository
  - echo "Installing Docker" > /tmp/cloud-init-status
  - mkdir -p /etc/apt/keyrings
  - curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /etc/apt/keyrings/docker.gpg
  - echo "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null
  - apt-get update
  - apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
  - systemctl enable docker
  - systemctl start docker
  - usermod -aG docker {config.username()}
  - docker --version
  - docker compose version
  
  - echo "SSH key setup" > /tmp/cloud-init-status
  # Ensure SSH directory is properly set up
  - mkdir -p /home/{config.username()}/.ssh
  - echo "{public_key}" > /home/{config.username()}/.ssh/authorized_keys
  - chown -R {config.username()}:{config.username()} /home/{config.username()}/.ssh
  - chmod 700 /home/{config.username()}/.ssh
  - chmod 600 /home/{config.username()}/.ssh/authorized_keys
  
  
  - echo "Finalizing setup" > /tmp/cloud-init-status
  
  # Signal that instance is ready
  - echo "Cloud-init finalizing" > /tmp/cloud-init-status
  - echo "[$(date)] All configurations complete" >> /var/log/startup-progress.log
  - echo "Instance setup complete" > /tmp/setup_complete
  - chown {config.username()}:{config.username()} /tmp/setup_complete
  - echo "Ready for connections" > /tmp/cloud-init-status
  
  # Create a marker file to signal cloud-init completion
  - echo "[$(date)] Cloud-init base setup complete" > /tmp/cloud-init-complete
  - echo "Base setup complete" > /tmp/cloud-init-status
  
  # Ensure Docker is fully installed and running
  - |
    echo "Verifying Docker installation..." >> /var/log/startup-progress.log
    for i in {{1..30}}; do
      if systemctl is-active --quiet docker && docker --version && docker compose version; then
        echo "Docker verified as working" >> /var/log/startup-progress.log
        break
      else
        echo "Waiting for Docker to be ready... (attempt $i/30)" >> /var/log/startup-progress.log
        sleep 2
      fi
    done
  
  # Signal completion
  - echo "[$(date)] Cloud-init initial setup complete" >> /var/log/startup-progress.log
  - echo "[$(date)] Waiting for file upload and service configuration" >> /opt/startup.log
  
# Note: We do NOT reboot here. Services will start naturally after files are uploaded.
"""

    return cloud_init_script


def generate_full_cloud_init(config: SimpleConfig) -> str:
    """Generate minimal cloud-init that waits for deployment bundle."""
    
    # Get public SSH key content
    public_key = config.public_ssh_key_content()
    if not public_key:
        rich_warning("No public SSH key found - SSH access may not work")
        public_key = ""
    
    # Read orchestrator credentials if they exist
    orchestrator_endpoint = ""
    orchestrator_token = ""
    files_dir = config.files_directory()
    
    try:
        endpoint_file = os.path.join(files_dir, "orchestrator_endpoint")
        if os.path.exists(endpoint_file):
            with open(endpoint_file, 'r') as f:
                orchestrator_endpoint = f.read().strip()
                # Ensure proper format
                if orchestrator_endpoint and not orchestrator_endpoint.startswith("nats://"):
                    if ":" not in orchestrator_endpoint:
                        orchestrator_endpoint = f"nats://{orchestrator_endpoint}:4222"
                    else:
                        orchestrator_endpoint = f"nats://{orchestrator_endpoint}"
        
        token_file = os.path.join(files_dir, "orchestrator_token")
        if os.path.exists(token_file):
            with open(token_file, 'r') as f:
                orchestrator_token = f.read().strip()
    except Exception as e:
        rich_warning(f"Could not read orchestrator credentials: {e}")
    
    # Build minimal cloud-init that waits for files
    cloud_init = f"""#cloud-config

users:
  - name: {config.username()}
    sudo: ALL=(ALL) NOPASSWD:ALL
    shell: /bin/bash
    ssh_authorized_keys:
      - {public_key}
    groups: docker

package_update: true
packages:
  - python3
  - python3-pip
  - wget
  - curl
  - jq
  - ca-certificates
  - gnupg
  - lsb-release
  - apt-transport-https
  - software-properties-common

write_files:
  - path: /opt/startup.log
    content: |
      Cloud-init started
    owner: root:root
    permissions: '0666'

  - path: /opt/orchestrator_endpoint
    content: |
      {orchestrator_endpoint}
    owner: root:root
    permissions: '0644'
    
  - path: /opt/orchestrator_token
    content: |
      {orchestrator_token}
    owner: root:root
    permissions: '0600'

  - path: /opt/setup_deployment.sh
    content: |
      #!/bin/bash
      # This script runs after reboot to set up all services
      
      echo "[$(date)] Starting deployment setup" | tee -a /opt/startup.log
      
      # Extract deployment bundle
      if [ ! -f /opt/deployment-bundle.tar.gz ]; then
          echo "[$(date)] ERROR: Deployment bundle not found!" | tee -a /opt/startup.log
          exit 1
      fi
      
      echo "[$(date)] Extracting deployment bundle..." | tee -a /opt/startup.log
      cd /opt
      tar -xzf deployment-bundle.tar.gz
      
      # Move files to correct locations
      echo "[$(date)] Installing files..." | tee -a /opt/startup.log
      
      # Copy configs
      if [ -d /opt/config ]; then
          mkdir -p /opt/uploaded_files/config
          cp -r /opt/config/* /opt/uploaded_files/config/
      fi
      
      # Copy scripts
      if [ -d /opt/scripts ]; then
          mkdir -p /opt/uploaded_files/scripts
          cp -r /opt/scripts/* /opt/uploaded_files/scripts/
          chmod +x /opt/uploaded_files/scripts/*.sh
          chmod +x /opt/uploaded_files/scripts/*.py
      fi
      
      # Copy credential files
      cp /opt/orchestrator_endpoint /opt/uploaded_files/
      cp /opt/orchestrator_token /opt/uploaded_files/
      chmod 600 /opt/uploaded_files/orchestrator_token
      
      # Create required directories
      mkdir -p /bacalhau_node /bacalhau_data
      mkdir -p /opt/sensor/{{config,data,logs,exports}}
      chown -R ubuntu:ubuntu /opt/uploaded_files /bacalhau_node /bacalhau_data /opt/sensor
      
      # Install systemd services
      echo "[$(date)] Installing systemd services..." | tee -a /opt/startup.log
      cp /opt/uploaded_files/scripts/*.service /etc/systemd/system/ 2>/dev/null || true
      systemctl daemon-reload
      
      # Ensure uv is in PATH for systemd services
      echo 'PATH="/home/ubuntu/.local/bin:/usr/local/bin:/usr/bin:/bin:/usr/sbin:/sbin"' >> /etc/environment
      
      # Start services in order
      echo "[$(date)] Starting services..." | tee -a /opt/startup.log
      
      # Start bacalhau-startup first
      systemctl enable bacalhau-startup.service
      systemctl start bacalhau-startup.service
      
      # Wait for startup to complete
      sleep 10
      
      # Check if services are running
      echo "[$(date)] Checking Docker containers..." | tee -a /opt/startup.log
      docker ps | tee -a /opt/startup.log
      
      # Check if bacalhau is running
      if docker ps | grep -q bacalhau; then
          echo "[$(date)] SUCCESS: Bacalhau container is running" | tee -a /opt/startup.log
      else
          echo "[$(date)] WARNING: Bacalhau container not found" | tee -a /opt/startup.log
      fi
      
      echo "[$(date)] Deployment setup complete" | tee -a /opt/startup.log
    owner: root:root
    permissions: '0755'

  - path: /etc/systemd/system/setup-deployment.service
    content: |
      [Unit]
      Description=Setup deployment after reboot
      After=network-online.target docker.service cloud-init.service
      Requires=docker.service
      
      [Service]
      Type=oneshot
      ExecStart=/opt/setup_deployment.sh
      RemainAfterExit=yes
      StandardOutput=journal+console
      StandardError=journal+console
      TimeoutStartSec=600
      Restart=on-failure
      RestartSec=30
      
      [Install]
      WantedBy=multi-user.target
    owner: root:root
    permissions: '0644'

runcmd:
  # Install Docker from official repository
  - |
    curl -fsSL https://download.docker.com/linux/ubuntu/gpg | gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg
    echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | tee /etc/apt/sources.list.d/docker.list > /dev/null
    apt-get update -qq
    apt-get install -qq -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin
    usermod -aG docker ubuntu
    systemctl enable docker
    systemctl start docker
  
  # Install uv for Python dependency management system-wide
  - curl -LsSf https://astral.sh/uv/install.sh | env UV_INSTALL_DIR="/usr/local/bin" sh
  - chmod 755 /usr/local/bin/uv
  
  # Wait for deployment bundle upload
  - echo "[$(date)] Waiting for deployment bundle upload..." | tee -a /opt/startup.log
  - |
    TIMEOUT=600
    ELAPSED=0
    while [ ! -f /tmp/UPLOAD_COMPLETE ] && [ $ELAPSED -lt $TIMEOUT ]; do
        echo "[$(date)] Still waiting... ($ELAPSED/$TIMEOUT seconds)" | tee -a /opt/startup.log
        sleep 10
        ELAPSED=$((ELAPSED + 10))
    done
    
    if [ ! -f /tmp/UPLOAD_COMPLETE ]; then
        echo "[$(date)] ERROR: Timeout waiting for upload!" | tee -a /opt/startup.log
        exit 1
    fi
    
    echo "[$(date)] Upload complete marker detected" | tee -a /opt/startup.log
    
    # Move bundle to final location
    if [ -f /tmp/deployment-bundle.tar.gz ]; then
        mv /tmp/deployment-bundle.tar.gz /opt/
        echo "[$(date)] Bundle moved to /opt/" | tee -a /opt/startup.log
    fi
    
    # Enable the setup service to run
    systemctl enable setup-deployment.service
    echo "[$(date)] Setup service enabled" | tee -a /opt/startup.log
    
    # Start the service immediately
    echo "[$(date)] Starting deployment setup..." | tee -a /opt/startup.log
    systemctl start setup-deployment.service
"""
    
    return cloud_init


def create_deployment_bundle(config: SimpleConfig) -> str:
    """Create a tar.gz bundle of all deployment files."""
    import tempfile
    
    bundle_file = os.path.join(tempfile.gettempdir(), "deployment-bundle.tar.gz")
    
    with tarfile.open(bundle_file, "w:gz") as tar:
        # Add scripts
        scripts_dir = config.scripts_directory()
        if os.path.exists(scripts_dir):
            for file in os.listdir(scripts_dir):
                filepath = os.path.join(scripts_dir, file)
                if os.path.isfile(filepath):
                    tar.add(filepath, arcname=f"scripts/{file}")
        
        # Add configs
        config_dir = "instance/config"
        if os.path.exists(config_dir):
            for file in os.listdir(config_dir):
                filepath = os.path.join(config_dir, file)
                if os.path.isfile(filepath):
                    tar.add(filepath, arcname=f"config/{file}")
        
        # Add other files (except credentials)
        files_dir = config.files_directory()
        if os.path.exists(files_dir):
            for file in os.listdir(files_dir):
                if file in ["orchestrator_endpoint", "orchestrator_token"]:
                    continue
                filepath = os.path.join(files_dir, file)
                if os.path.isfile(filepath):
                    tar.add(filepath, arcname=f"files/{file}")
    
    return bundle_file


def upload_deployment_bundle(hostname: str, username: str, private_key_path: str, bundle_file: str, logger=None) -> bool:
    """Upload deployment bundle to instance and create completion marker."""
    
    # Upload bundle to /tmp
    bundle_temp_path = "/tmp/deployment-bundle.tar.gz"
    marker_path = "/tmp/UPLOAD_COMPLETE"
    
    scp_command = [
        "scp",
        "-i", private_key_path,
        "-o", "StrictHostKeyChecking=no",
        "-o", "UserKnownHostsFile=/dev/null",
        "-o", "ConnectTimeout=10",
        bundle_file,
        f"{username}@{hostname}:{bundle_temp_path}"
    ]
    
    try:
        # Upload bundle
        result = subprocess.run(scp_command, capture_output=True, text=True, timeout=60)
        if result.returncode != 0:
            if logger:
                logger.error(f"Failed to upload bundle: {result.stderr}")
            return False
        
        # Create completion marker
        ssh_command = [
            "ssh",
            "-i", private_key_path,
            "-o", "StrictHostKeyChecking=no",
            "-o", "UserKnownHostsFile=/dev/null",
            f"{username}@{hostname}",
            f"touch {marker_path}"
        ]
        
        result = subprocess.run(ssh_command, capture_output=True, text=True, timeout=30)
        if result.returncode == 0:
            if logger:
                logger.info(f"Successfully uploaded bundle to {hostname}")
            return True
        else:
            if logger:
                logger.error(f"Failed to create upload marker: {result.stderr}")
            return False
            
    except subprocess.TimeoutExpired:
        if logger:
            logger.error("Upload timed out after 60 seconds")
        return False
    except Exception as e:
        if logger:
            logger.error(f"Upload failed: {e}")
        return False

def wait_for_instance_ready(
    hostname: str,
    username: str,
    private_key_path: str,
    timeout: int = 300,
    instance_key: str = None,
    update_status_func=None,
    progress_callback=None,
    config=None,
) -> bool:
    """Wait for SSH to be ready and for cloud-init to finish with detailed progress tracking."""
    start_time = time.time()
    ssh_ready = False
    last_log_time = 0

    def update_progress(phase, progress, status=""):
        if progress_callback and instance_key:
            progress_callback(instance_key, phase, progress, status)
        if update_status_func and instance_key:
            update_status_func(instance_key, f"{phase}: {status}")

    update_progress("SSH: Connection", 0, "Starting SSH connection check...")

    while time.time() - start_time < timeout:
        elapsed = int(time.time() - start_time)

        # Phase 1: Wait for SSH
        if not ssh_ready:
            update_progress(
                "SSH: Connection", 10, f"Attempting SSH connection... ({elapsed}s)"
            )
            try:
                result = subprocess.run(
                    [
                        "ssh",
                        "-i",
                        private_key_path,
                        "-o",
                        "StrictHostKeyChecking=no",
                        "-o",
                        "UserKnownHostsFile=/dev/null",
                        "-o",
                        "ConnectTimeout=5",
                        f"{username}@{hostname}",
                        'echo "SSH ready"',
                    ],
                    capture_output=True,
                    text=True,
                    timeout=5,
                )
                if result.returncode == 0:
                    ssh_ready = True
                    update_progress(
                        "SSH: Connection", 100, "SSH connection established"
                    )
                    time.sleep(2)  # Brief pause before cloud-init check
                    
                    # Upload deployment bundle after SSH is ready
                    if elapsed > 20 and config:  # Give cloud-init time to set up
                        # Create bundle once
                        if not hasattr(wait_for_instance_ready, '_bundle_file'):
                            update_progress("Bundle", 60, "Creating deployment bundle...")
                            wait_for_instance_ready._bundle_file = create_deployment_bundle(config)
                        
                        # Upload bundle
                        update_progress("Upload", 70, "Uploading deployment files...")
                        if upload_deployment_bundle(hostname, username, private_key_path, 
                                                   wait_for_instance_ready._bundle_file):
                            update_progress("Upload", 85, "Deployment files uploaded")
                            # Give the instance time to extract and start services
                            time.sleep(5)
                            return True
                        else:
                            update_progress("Upload", 70, "Upload failed, retrying...")
                    continue
                else:
                    update_progress(
                        "SSH: Connection",
                        20 + (elapsed * 2),
                        f"SSH not ready... ({elapsed}s)",
                    )
            except (subprocess.TimeoutExpired, Exception):
                update_progress(
                    "SSH: Connection",
                    20 + (elapsed * 2),
                    f"SSH connection failed... ({elapsed}s)",
                )

        # Phase 2: SSH is up, check for cloud-init progress
        if ssh_ready:
            # Occasionally stream live logs for better UX
            current_time = time.time()
            if current_time - last_log_time > 8:  # Every 8 seconds
                last_log_time = current_time
                try:
                    # Get latest meaningful log line
                    log_cmd = 'tail -5 /var/log/cloud-init-output.log 2>/dev/null | grep -E "(Setting up|Installing|Running|Starting|Configuring)" | tail -1'
                    log_result = subprocess.run(
                        [
                            "ssh",
                            "-i",
                            private_key_path,
                            "-o",
                            "StrictHostKeyChecking=no",
                            "-o",
                            "UserKnownHostsFile=/dev/null",
                            "-o",
                            "ConnectTimeout=2",
                            f"{username}@{hostname}",
                            log_cmd,
                        ],
                        capture_output=True,
                        text=True,
                        timeout=3,
                    )
                    if log_result.returncode == 0 and log_result.stdout.strip():
                        log_line = log_result.stdout.strip()[:60]  # Truncate
                        update_progress("Cloud-Init", 0, f"ðŸ“¦ {log_line}")
                except Exception:
                    pass

            update_progress("Cloud-Init", 0, "Checking cloud-init status...")
            try:
                # Enhanced status checking with multiple sources
                check_commands = [
                    'test -f /tmp/setup_complete && echo "SETUP_COMPLETE"',
                    "cat /tmp/cloud-init-status 2>/dev/null",
                    'cloud-init status 2>/dev/null | grep -o "status:.*" | cut -d: -f2',
                    "systemctl is-active docker 2>/dev/null",
                    "tail -1 /var/log/startup-progress.log 2>/dev/null",
                ]

                combined_command = ' && echo "|||" && '.join(check_commands)
                result = subprocess.run(
                    [
                        "ssh",
                        "-i",
                        private_key_path,
                        "-o",
                        "StrictHostKeyChecking=no",
                        "-o",
                        "UserKnownHostsFile=/dev/null",
                        "-o",
                        "ConnectTimeout=5",
                        f"{username}@{hostname}",
                        f'bash -c "{combined_command}"',
                    ],
                    capture_output=True,
                    text=True,
                    timeout=6,
                )

                if result.returncode == 0:
                    outputs = result.stdout.strip().split("|||")

                    # Check if setup is complete
                    if len(outputs) > 0 and "SETUP_COMPLETE" in outputs[0]:
                        update_progress("Cloud-Init", 100, "Cloud-init complete")
                        update_progress(
                            "Instance Ready", 100, "Instance is fully ready âœ…"
                        )
                        return True

                    # Parse status from different sources
                    status_msg = "Initializing..."
                    progress = 20

                    if len(outputs) > 1 and outputs[1]:
                        cloud_status = outputs[1].strip()
                        if "Docker setup" in cloud_status:
                            status_msg = "Installing Docker..."
                            progress = 40
                        elif "SSH key setup" in cloud_status:
                            status_msg = "Configuring SSH keys..."
                            progress = 35
                        elif "Installing uv" in cloud_status:
                            status_msg = "Installing package manager..."
                            progress = 50
                        elif "Package updates" in cloud_status:
                            status_msg = "Updating packages..."
                            progress = 30
                        elif "Cloud-init finalizing" in cloud_status:
                            status_msg = "Finalizing setup..."
                            progress = 90
                        elif "Ready for connections" in cloud_status:
                            status_msg = "Almost ready..."
                            progress = 95
                        else:
                            status_msg = cloud_status[:50]
                            progress = 60

                    # Check cloud-init official status
                    if len(outputs) > 2 and outputs[2]:
                        ci_status = outputs[2].strip()
                        if "done" in ci_status:
                            progress = max(progress, 85)
                            status_msg = "Cloud-init finishing up..."
                        elif "running" in ci_status:
                            progress = max(progress, 25)

                    # Check Docker status
                    if len(outputs) > 3 and outputs[3] == "active":
                        progress = max(progress, 70)
                        if progress == 70:
                            status_msg = "Docker is ready"

                    # Check startup progress log
                    if len(outputs) > 4 and outputs[4]:
                        startup_log = outputs[4].strip()
                        if "Docker installed" in startup_log:
                            progress = max(progress, 45)
                        elif "SSH keys configured" in startup_log:
                            progress = max(progress, 38)
                        elif "UV package manager installed" in startup_log:
                            progress = max(progress, 55)
                        elif "All configurations complete" in startup_log:
                            progress = max(progress, 92)

                    # Add elapsed time to status
                    if elapsed > 30:
                        status_msg = f"{status_msg} ({elapsed}s)"

                    update_progress("Cloud-Init", progress, status_msg)
                else:
                    update_progress("Cloud-Init", 15, "Waiting for cloud-init...")

            except (subprocess.TimeoutExpired, Exception):
                update_progress("Cloud-Init", 10, "Checking cloud-init status...")

        time.sleep(5)

    update_progress("Timeout", 0, f"Timeout after {timeout}s")
    if update_status_func and instance_key:
        update_status_func(
            instance_key,
            "ERROR: Timeout waiting for instance to be ready.",
            is_final=True,
        )
    return False


def wait_for_instance_ready(
    hostname: str,
    username: str,
    private_key_path: str,
    timeout: int = 300,
    instance_key: str = None,
    update_status_func=None,
    progress_callback=None,
    config=None,
) -> bool:
    """Wait for SSH to be ready and for cloud-init to finish with detailed progress tracking."""
    start_time = time.time()
    ssh_ready = False
    last_log_time = 0

    def update_progress(phase, progress, status=""):
        if progress_callback and instance_key:
            progress_callback(instance_key, phase, progress, status)
        if update_status_func and instance_key:
            update_status_func(instance_key, f"{phase}: {status}")

    update_progress("SSH: Connection", 0, "Starting SSH connection check...")

    while time.time() - start_time < timeout:
        elapsed = int(time.time() - start_time)

        # Phase 1: Wait for SSH
        if not ssh_ready:
            update_progress(
                "SSH: Connection", 10, f"Attempting SSH connection... ({elapsed}s)"
            )
            try:
                result = subprocess.run(
                    [
                        "ssh",
                        "-i",
                        private_key_path,
                        "-o",
                        "StrictHostKeyChecking=no",
                        "-o",
                        "UserKnownHostsFile=/dev/null",
                        "-o",
                        "ConnectTimeout=5",
                        f"{username}@{hostname}",
                        'echo "SSH ready"',
                    ],
                    capture_output=True,
                    text=True,
                    timeout=5,
                )
                if result.returncode == 0:
                    ssh_ready = True
                    update_progress(
                        "SSH: Connection", 100, "SSH connection established"
                    )
                    time.sleep(2)  # Brief pause before cloud-init check
                    continue
                else:
                    update_progress(
                        "SSH: Connection",
                        20 + (elapsed * 2),
                        f"SSH not ready... ({elapsed}s)",
                    )
            except (subprocess.TimeoutExpired, Exception):
                update_progress(
                    "SSH: Connection",
                    20 + (elapsed * 2),
                    f"SSH connection failed... ({elapsed}s)",
                )

        # Phase 2: SSH is up, check for cloud-init progress
        if ssh_ready:
            # Check for the setup_complete marker file
            try:
                check_command = 'test -f /tmp/setup_complete && echo "SETUP_COMPLETE"'
                result = subprocess.run(
                    [
                        "ssh",
                        "-i",
                        private_key_path,
                        "-o",
                        "StrictHostKeyChecking=no",
                        "-o",
                        "UserKnownHostsFile=/dev/null",
                        "-o",
                        "ConnectTimeout=5",
                        f"{username}@{hostname}",
                        check_command,
                    ],
                    capture_output=True,
                    text=True,
                    timeout=6,
                )
                if result.returncode == 0 and "SETUP_COMPLETE" in result.stdout:
                    update_progress("Cloud-Init", 100, "Cloud-init complete")
                    update_progress(
                        "Instance Ready", 100, "Instance is fully ready âœ…"
                    )
                    return True
                else:
                    # If marker not found, get the latest status for display
                    log_cmd = 'tail -1 /tmp/cloud-init-status 2>/dev/null'
                    log_result = subprocess.run(
                        [
                            "ssh",
                            "-i",
                            private_key_path,
                            "-o",
                            "StrictHostKeyChecking=no",
                            "-o",
                            "UserKnownHostsFile=/dev/null",
                            "-o",
                            "ConnectTimeout=2",
                            f"{username}@{hostname}",
                            log_cmd,
                        ],
                        capture_output=True,
                        text=True,
                        timeout=3,
                    )
                    if log_result.returncode == 0 and log_result.stdout.strip():
                        log_line = log_result.stdout.strip()[:60]  # Truncate
                        update_progress("Cloud-Init", 50, f"ðŸ“¦ {log_line}")
                    else:
                        update_progress("Cloud-Init", 25, "Waiting for cloud-init...")

            except (subprocess.TimeoutExpired, Exception):
                update_progress("Cloud-Init", 10, "Checking cloud-init status...")

        time.sleep(5)

    update_progress("Timeout", 0, f"Timeout after {timeout}s")
    if update_status_func and instance_key:
        update_status_func(
            instance_key,
            "ERROR: Timeout waiting for instance to be ready.",
            is_final=True,
        )
    return False


def post_creation_setup(
    instances: List[Dict],
    config: SimpleConfig,
    update_status_func,
    logger,
    progress_callback=None,
):
    """Perform post-creation setup like uploading files and configuring services."""
    if not instances:
        return

    username = config.username()
    private_key_path = config.private_ssh_key_path()

    if not private_key_path or not os.path.exists(private_key_path):
        logger.error("Private SSH key not found, cannot perform post-creation setup.")
        return

    def setup_instance(instance):
        """Setup a single instance."""
        instance_id = instance["id"]
        ip = instance.get("public_ip")
        if not ip:
            logger.warning(f"No public IP for {instance_id}, skipping setup.")
            return

        update_status_func(instance_id, "WAIT: Instance ready...")
        if wait_for_instance_ready(
            ip,
            username,
            private_key_path,
            instance_key=instance_id,
            update_status_func=update_status_func,
            progress_callback=progress_callback,
            config=config,
        ):
            update_status_func(instance_id, "SETUP: Uploading files...")
            if upload_files_to_instance(ip, username, private_key_path, config, logger):
                update_status_func(instance_id, "SETUP: Enabling services...")
                if enable_startup_service(ip, username, private_key_path, logger):
                    update_status_func(instance_id, "SUCCESS: Deployment complete", is_final=True)
                else:
                    update_status_func(instance_id, "ERROR: Service enablement failed", is_final=True)
            else:
                update_status_func(instance_id, "ERROR: File upload failed", is_final=True)
        else:
            update_status_func(instance_id, "ERROR: Instance not ready", is_final=True)

    # Use a thread pool for concurrent setup
    with ThreadPoolExecutor(max_workers=10, thread_name_prefix="Setup") as executor:
        futures = [
            executor.submit(setup_instance, instance) for instance in instances
        ]
        for future in futures:
            future.result()  # Wait for all to complete


def ensure_remote_directories(
    hostname: str,
    username: str,
    private_key_path: str,
    logger=None,
    retry_count: int = 3,
) -> bool:
    """Ensure remote directories exist for file uploads with retry logic."""

    def log_info(message):
        if logger:
            logger.info(message)

    def log_error(message):
        if logger:
            logger.error(message)

    # Define the directories we need
    directories = [
        "/opt/uploaded_files",
        "/opt/uploaded_files/scripts",
        "/opt/uploaded_files/config",
        "/tmp/uploaded_files",
        "/tmp/uploaded_files/scripts",
        "/tmp/uploaded_files/config",
        "/tmp/exs",  # Temporary location for service files
    ]

    for attempt in range(retry_count):
        try:
            log_info(
                f"Directory creation attempt {attempt + 1}/{retry_count} on {hostname}"
            )

            # Build a robust command that handles various scenarios
            commands = []

            # First, try to create parent directories with sudo
            commands.append(
                "sudo mkdir -p /opt/uploaded_files /tmp/uploaded_files 2>/dev/null || true"
            )

            # Set ownership (might fail if no sudo, that's ok)
            commands.append(
                f"sudo chown -R {username}:{username} /opt/uploaded_files /tmp/uploaded_files 2>/dev/null || true"
            )

            # Create all subdirectories (as user, should always work for /tmp at least)
            for dir in directories:
                commands.append(f"mkdir -p {dir} 2>/dev/null || true")

            # Set permissions where we can
            commands.append("chmod -R 755 /opt/uploaded_files 2>/dev/null || true")
            commands.append("chmod -R 755 /tmp/uploaded_files 2>/dev/null || true")

            # Verify at least /tmp directories exist
            commands.append(
                "test -d /tmp/uploaded_files/scripts && test -d /tmp/uploaded_files/config && echo 'DIRS_OK' || echo 'DIRS_FAILED'"
            )

            full_command = " && ".join(commands)

            result = subprocess.run(
                [
                    "ssh",
                    "-i",
                    private_key_path,
                    "-o",
                    "StrictHostKeyChecking=no",
                    "-o",
                    "UserKnownHostsFile=/dev/null",
                    "-o",
                    "ConnectTimeout=10",
                    f"{username}@{hostname}",
                    full_command,
                ],
                capture_output=True,
                text=True,
                timeout=30,
            )

            # Check if at least the basic directories were created
            if "DIRS_OK" in result.stdout:
                log_info(f"Successfully created/verified directories on {hostname}")
                return True
            elif attempt < retry_count - 1:
                log_info(
                    f"Directory creation attempt {attempt + 1} failed, retrying..."
                )
                time.sleep(2)  # Brief pause before retry
            else:
                log_error(f"Failed to create directories after {retry_count} attempts")
                log_error(f"stdout: {result.stdout}")
                log_error(f"stderr: {result.stderr}")

        except Exception as e:
            log_error(f"Exception during directory creation attempt {attempt + 1}: {e}")
            if attempt < retry_count - 1:
                time.sleep(2)

    return False


def upload_files_to_instance(
    hostname: str,
    username: str,
    private_key_path: str,
    config: SimpleConfig,
    logger=None,
    progress_callback=None,
    instance_key=None,
) -> bool:
    """Upload files and scripts to the instance with progress tracking."""

    def log_error(message):
        if logger:
            logger.error(message)
        # Don't print to console in hands-off mode

    def update_progress(phase, progress, status=""):
        if progress_callback and instance_key:
            progress_callback(instance_key, phase, progress, status)
    
    def update_status(status):
        """Update status in the main table."""
        if hasattr(upload_files_to_instance, 'update_status_func') and instance_key:
            upload_files_to_instance.update_status_func(instance_key, status)

    try:
        # Upload files directory if it exists and is not empty
        files_dir = config.files_directory()
        if logger:
            logger.info(
                f"Files directory: {files_dir}, exists: {os.path.exists(files_dir)}"
            )

        if os.path.exists(files_dir) and os.listdir(files_dir):
            update_progress("SCP: Files Upload", 25, "Starting files upload...")

            # Count total files for progress calculation
            total_files = len(
                [
                    f
                    for f in os.listdir(files_dir)
                    if os.path.isfile(os.path.join(files_dir, f))
                ]
            )

            result = subprocess.run(
                [
                    "scp",
                    "-i",
                    private_key_path,
                    "-o",
                    "StrictHostKeyChecking=no",
                    "-o",
                    "UserKnownHostsFile=/dev/null",
                    "-o",
                    "ConnectTimeout=10",
                    "-r",
                    f"{files_dir}/.",
                    f"{username}@{hostname}:/opt/uploaded_files/",
                ],
                capture_output=True,
                text=True,
                timeout=120,  # Increased timeout for larger uploads
            )
            if result.returncode != 0:
                log_error(f"Failed to upload files to {hostname}: {result.stderr}")
                return False

            update_progress("SCP: Files Upload", 50, f"Uploaded {total_files} files")

        # Upload scripts directory if it exists and is not empty
        scripts_dir = config.scripts_directory()
        if os.path.exists(scripts_dir) and os.listdir(scripts_dir):
            update_progress("SCP: Scripts Upload", 55, "Starting scripts upload...")
            
            # First, upload service files to /tmp/exs
            service_files = [
                "bacalhau-startup.service",
                "setup-config.service", 
                "bacalhau.service",
                "sensor-generator.service"
            ]
            
            # Upload service files to /tmp/exs
            update_status("UPLOAD: Service files to /tmp/exs...")
            for service_file in service_files:
                service_path = os.path.join(scripts_dir, service_file)
                if os.path.exists(service_path):
                    result = subprocess.run(
                        [
                            "scp",
                            "-i",
                            private_key_path,
                            "-o",
                            "StrictHostKeyChecking=no",
                            "-o",
                            "UserKnownHostsFile=/dev/null",
                            "-o",
                            "ConnectTimeout=10",
                            service_path,
                            f"{username}@{hostname}:/tmp/exs/",
                        ],
                        capture_output=True,
                        text=True,
                        timeout=30,
                    )
                    if result.returncode != 0:
                        log_error(f"Failed to upload {service_file} to /tmp/exs: {result.stderr}")
                        return False
            
            update_progress("SCP: Service Files", 60, "Service files uploaded to /tmp/exs")
            
            # Upload all scripts to /tmp/exs (including non-service files)
            update_status("UPLOAD: All scripts to /tmp/exs...")
            result = subprocess.run(
                [
                    "scp",
                    "-i",
                    private_key_path,
                    "-o",
                    "StrictHostKeyChecking=no",
                    "-o",
                    "UserKnownHostsFile=/dev/null",
                    "-o",
                    "ConnectTimeout=10",
                    "-r",
                    f"{scripts_dir}/.",
                    f"{username}@{hostname}:/tmp/exs/",
                ],
                capture_output=True,
                text=True,
                timeout=120,
            )
            if result.returncode != 0:
                log_error(f"Failed to upload scripts to /tmp/exs: {result.stderr}")
                return False
                
            update_progress("SCP: Scripts Upload", 70, "All scripts uploaded to /tmp/exs")

            # Also copy to /tmp for backward compatibility
            subprocess.run(
                [
                    "scp",
                    "-i",
                    private_key_path,
                    "-o",
                    "StrictHostKeyChecking=no",
                    "-o",
                    "UserKnownHostsFile=/dev/null",
                    "-o",
                    "ConnectTimeout=10",
                    "-r",
                    f"{scripts_dir}/.",
                    f"{username}@{hostname}:/tmp/uploaded_files/scripts/",
                ],
                capture_output=True,
                text=True,
                timeout=120,
            )

            update_progress(
                "SCP: Scripts Upload", 80, "Scripts copied to both locations"
            )

        # Upload config directory if it exists
        config_dir = os.path.join(os.path.dirname(scripts_dir), "config")
        if os.path.exists(config_dir) and os.listdir(config_dir):
            update_progress("SCP: Config Upload", 85, "Uploading config files...")

            result = subprocess.run(
                [
                    "scp",
                    "-i",
                    private_key_path,
                    "-o",
                    "StrictHostKeyChecking=no",
                    "-o",
                    "UserKnownHostsFile=/dev/null",
                    "-o",
                    "ConnectTimeout=10",
                    "-r",
                    f"{config_dir}/.",
                    f"{username}@{hostname}:/opt/uploaded_files/config/",
                ],
                capture_output=True,
                text=True,
                timeout=120,
            )

            # Also copy to /tmp for backward compatibility
            subprocess.run(
                [
                    "scp",
                    "-i",
                    private_key_path,
                    "-o",
                    "StrictHostKeyChecking=no",
                    "-o",
                    "UserKnownHostsFile=/dev/null",
                    "-o",
                    "ConnectTimeout=10",
                    "-r",
                    f"{config_dir}/.",
                    f"{username}@{hostname}:/tmp/uploaded_files/config/",
                ],
                capture_output=True,
                text=True,
                timeout=120,
            )

            update_progress("SCP: Config Upload", 95, "Config files uploaded")

        update_progress("SCP: Complete", 100, "All files uploaded successfully")
        return True

    except Exception as e:
        log_error(f"Exception during file upload to {hostname}: {e}")
        update_progress("SCP: Error", 0, f"Failed: {str(e)}")
        return False


def wait_for_ssh_only(
    hostname: str, username: str, private_key_path: str, timeout: int = 120
) -> bool:
    """Simple SSH availability check - no cloud-init monitoring."""
    start_time = time.time()

    while time.time() - start_time < timeout:
        try:
            result = subprocess.run(
                [
                    "ssh",
                    "-i",
                    private_key_path,
                    "-o",
                    "StrictHostKeyChecking=no",
                    "-o",
                    "UserKnownHostsFile=/dev/null",
                    "-o",
                    "ConnectTimeout=5",
                    f"{username}@{hostname}",
                    'echo "SSH ready"',
                ],
                capture_output=True,
                text=True,
                timeout=10,
            )
            if result.returncode == 0:
                return True
        except Exception:
            pass
        time.sleep(5)

    return False


def enable_startup_service(
    hostname: str, username: str, private_key_path: str, logger=None
) -> bool:
    """Execute the deployment script to configure services."""
    try:
        # First, upload the deploy_services.py script
        deploy_script_path = os.path.join(
            os.path.dirname(__file__), "instance/scripts/deploy_services.py"
        )
        
        if os.path.exists(deploy_script_path):
            # Upload the deployment script
            scp_command = [
                "scp",
                "-i", private_key_path,
                "-o", "StrictHostKeyChecking=no",
                "-o", "UserKnownHostsFile=/dev/null",
                deploy_script_path,
                f"{username}@{hostname}:/tmp/deploy_services.py"
            ]
            
            result = subprocess.run(scp_command, capture_output=True, text=True)
            if result.returncode != 0:
                if logger:
                    logger.info(f"Failed to upload deployment script: {result.stderr}")
                return False
                
        # Execute the deployment script
        commands = [
            # Make the script executable
            "chmod +x /tmp/deploy_services.py",
            # Run the deployment script with sudo
            "sudo python3 /tmp/deploy_services.py",
        ]

        full_command = " && ".join(commands)

        result = subprocess.run(
            [
                "ssh",
                "-i",
                private_key_path,
                "-o",
                "StrictHostKeyChecking=no",
                "-o",
                "UserKnownHostsFile=/dev/null",
                f"{username}@{hostname}",
                full_command,
            ],
            capture_output=True,
            text=True,
            timeout=120,  # Increased timeout for configure-services to run
        )

        if logger:
            logger.info(f"Service configuration stdout: {result.stdout}")
            if result.stderr:
                logger.info(f"Service configuration stderr: {result.stderr}")
            logger.info(f"Service configuration return code: {result.returncode}")

        # More flexible success check
        success = (
            result.returncode == 0 
            or "Services installed successfully" in result.stdout
            or "Configuration attempt complete" in result.stdout
        )
        
        return success

    except subprocess.TimeoutExpired:
        if logger:
            logger.warning("Service configuration timed out - this may be normal")
        return True  # Don't fail on timeout, services may still be configuring
    except Exception as e:
        if logger:
            logger.error(f"Error configuring services: {e}")
        return False


def verify_cloud_init_running(
    hostname: str, username: str, private_key_path: str, logger=None
) -> bool:
    """Quick check that cloud-init is running - no waiting."""
    try:
        result = subprocess.run(
            [
                "ssh",
                "-i",
                private_key_path,
                "-o",
                "StrictHostKeyChecking=no",
                "-o",
                "UserKnownHostsFile=/dev/null",
                "-o",
                "ConnectTimeout=5",
                f"{username}@{hostname}",
                "cloud-init status | grep -E 'status:|running' || ps aux | grep cloud-init | grep -v grep",
            ],
            capture_output=True,
            text=True,
            timeout=10,
        )

        if logger:
            logger.info(f"Cloud-init check: {result.stdout}")

        return "running" in result.stdout.lower() or "cloud-init" in result.stdout

    except Exception as e:
        if logger:
            logger.warning(f"Could not verify cloud-init: {e}")
        return False





# =============================================================================
# CORE SPOT INSTANCE MANAGEMENT
# =============================================================================


def create_simple_security_group(ec2, vpc_id: str) -> str:
    """Create basic security group."""
    try:
        # Check for existing security group
        response = ec2.describe_security_groups(
            Filters=[
                {"Name": "vpc-id", "Values": [vpc_id]},
                {"Name": "group-name", "Values": ["spot-deployer-sg"]},
            ]
        )

        if response["SecurityGroups"]:
            return response["SecurityGroups"][0]["GroupId"]

        # Create new security group
        response = ec2.create_security_group(
            GroupName="spot-deployer-sg",
            Description="Simple security group for spot instances",
            VpcId=vpc_id,
        )
        sg_id = response["GroupId"]

        # Add basic rules
        ec2.authorize_security_group_ingress(
            GroupId=sg_id,
            IpPermissions=[
                {
                    "IpProtocol": "tcp",
                    "FromPort": 22,
                    "ToPort": 22,
                    "IpRanges": [{"CidrIp": "0.0.0.0/0"}],
                },
                {
                    "IpProtocol": "tcp",
                    "FromPort": 4222,
                    "ToPort": 4222,
                    "IpRanges": [{"CidrIp": "0.0.0.0/0"}],
                },
            ],
        )

        return sg_id
    except Exception as e:
        print(f"Error creating security group: {e}")
        raise


def create_instances_in_region(
    config: SimpleConfig, region: str, count: int, progress=None, task=None
) -> List[Dict]:
    """Create spot instances in a specific region."""
    if count <= 0:
        return []

    def update_progress(message: str):
        """Update progress bar if available, otherwise use rich_status."""
        if progress and task is not None:
            progress.update(task, description=message)
            time.sleep(0.2)  # Brief pause to show progress
        else:
            rich_status(message)

    update_progress(f"ðŸ” Looking for VPC in {region}...")

    try:
        ec2 = boto3.client("ec2", region_name=region)

        # Get default VPC
        vpcs = ec2.describe_vpcs(Filters=[{"Name": "is-default", "Values": ["true"]}])
        if not vpcs["Vpcs"]:
            update_progress(f"ðŸ” No default VPC in {region}, checking all VPCs...")
            # Try any VPC if no default exists
            all_vpcs = ec2.describe_vpcs()
            if all_vpcs["Vpcs"]:
                vpc_id = all_vpcs["Vpcs"][0]["VpcId"]
                update_progress(f"ðŸ—ï¸  Using VPC {vpc_id} in {region}")
            else:
                rich_warning(f"No VPCs found in {region}, skipping")
                return []
        else:
            vpc_id = vpcs["Vpcs"][0]["VpcId"]
            update_progress(f"ðŸ—ï¸  Using default VPC {vpc_id} in {region}")

        # Get default subnet
        update_progress(f"ðŸ” Looking for subnet in VPC {vpc_id}...")
        subnets = ec2.describe_subnets(
            Filters=[
                {"Name": "vpc-id", "Values": [vpc_id]},
                {"Name": "default-for-az", "Values": ["true"]},
            ]
        )
        if not subnets["Subnets"]:
            update_progress(f"ðŸ” No default subnet in {region}, trying any subnet...")
            # Try any subnet in the VPC
            all_subnets = ec2.describe_subnets(
                Filters=[{"Name": "vpc-id", "Values": [vpc_id]}]
            )
            if all_subnets["Subnets"]:
                subnet_id = all_subnets["Subnets"][0]["SubnetId"]
                update_progress(f"ðŸŒ Using subnet {subnet_id} in {region}")
            else:
                rich_warning(f"No subnets found in VPC {vpc_id}, skipping")
                return []
        else:
            subnet_id = subnets["Subnets"][0]["SubnetId"]
            update_progress(f"ðŸŒ Using default subnet {subnet_id} in {region}")

        # Create security group
        update_progress(f"ðŸ”’ Creating security group in {region}...")
        sg_id = create_simple_security_group(ec2, vpc_id)

        # Get AMI
        update_progress(f"ðŸ“€ Getting AMI for {region}...")
        ami_id = get_latest_ubuntu_ami(region)
        if not ami_id:
            rich_warning(f"No AMI found for {region}, skipping")
            return []

        # Get instance type
        region_config = config.region_config(region)
        instance_type = region_config.get("machine_type", "t3.medium")

        # Create user data script
        user_data = f"""#!/bin/bash
apt-get update
apt-get install -y docker.io
systemctl enable docker
systemctl start docker
usermod -aG docker {config.username()}
"""

        # Create spot instance request
        update_progress(f"ðŸš€ Requesting spot instances in {region}...")
        spot_request = {
            "ImageId": ami_id,
            "InstanceType": instance_type,
            "SecurityGroupIds": [sg_id],
            "SubnetId": subnet_id,
            "UserData": base64.b64encode(user_data.encode()).decode(),
        }

        # Add SSH key if configured
        ssh_key = config.ssh_key_name()
        if ssh_key:
            spot_request["KeyName"] = ssh_key

        # Request spot instances
        response = ec2.request_spot_instances(
            InstanceCount=count, LaunchSpecification=spot_request, Type="one-time"
        )

        spot_request_ids = [
            req["SpotInstanceRequestId"] for req in response["SpotInstanceRequests"]
        ]
        update_progress(f"â³ Waiting for spot instances to launch in {region}...")

        # Wait for fulfillment (simplified - max 5 minutes)
        instances = []
        for attempt in range(30):  # 30 * 10s = 5 minutes max
            try:
                spot_response = ec2.describe_spot_instance_requests(
                    SpotInstanceRequestIds=spot_request_ids
                )

                active_requests = [
                    req
                    for req in spot_response["SpotInstanceRequests"]
                    if req["State"] == "active" and "InstanceId" in req
                ]

                if len(active_requests) == count:
                    update_progress(f"ðŸ·ï¸  Tagging instances in {region}...")
                    # Get instance details
                    instance_ids = [req["InstanceId"] for req in active_requests]
                    instance_response = ec2.describe_instances(InstanceIds=instance_ids)

                    for reservation in instance_response["Reservations"]:
                        for instance in reservation["Instances"]:
                            instances.append(
                                {
                                    "id": instance["InstanceId"],
                                    "region": region,
                                    "type": instance["InstanceType"],
                                    "state": instance["State"]["Name"],
                                    "public_ip": instance.get("PublicIpAddress", ""),
                                    "private_ip": instance.get("PrivateIpAddress", ""),
                                    "created": datetime.now().isoformat(),
                                }
                            )

                    # Tag instances
                    if instance_ids:
                        ec2.create_tags(
                            Resources=instance_ids,
                            Tags=[
                                {"Key": "ManagedBy", "Value": "SpotDeployer"},
                                {"Key": "Name", "Value": f"SpotInstance-{region}"},
                            ],
                        )

                    break

                # Check for failed requests
                failed = [
                    req
                    for req in spot_response["SpotInstanceRequests"]
                    if req["State"] in ["failed", "cancelled"]
                ]
                if failed:
                    rich_error(f"Some spot requests failed in {region}")
                    break

                # Update progress with wait time
                update_progress(
                    f"â³ Waiting for spot instances to launch in {region}... (attempt {attempt + 1}/30)"
                )
                time.sleep(10)

            except Exception as e:
                rich_error(f"Error checking spot requests: {e}")
                break

        if not instances:
            rich_warning(f"No instances created in {region} (timeout or failure)")

        return instances

    except Exception as e:
        rich_error(f"Error creating instances in {region}: {e}")
        return []


def create_instances_in_region_with_table(
    config: SimpleConfig,
    region: str,
    count: int,
    creation_status: Dict,
    lock: threading.Lock,
    logger,
    update_status_func,
) -> List[Dict]:
    """Create spot instances in a specific region with live table updates."""
    if count <= 0:
        return []

    instance_keys = [f"{region}-{i + 1}" for i in range(count)]

    def log_message(msg: str):
        """Thread-safe logging to file."""
        logger.info(msg)

    for key in instance_keys:
        update_status_func(key, "Finding VPC")

    try:
        ec2 = boto3.client("ec2", region_name=region)

        # Check cache first
        vpc_id = None
        with CACHE_LOCK:
            if region in VPC_CACHE:
                vpc_id = VPC_CACHE[region]
                log_message(f"[{region}] Using cached VPC {vpc_id}")
                for key in instance_keys:
                    update_status_func(key, "Using cached VPC")
        
        if not vpc_id:
            log_message(f"[{region}] Looking for VPC...")
            vpcs = ec2.describe_vpcs(Filters=[{"Name": "is-default", "Values": ["true"]}])
            if not vpcs["Vpcs"]:
                for key in instance_keys:
                    update_status_func(key, "Finding any VPC")
                log_message(f"[{region}] No default VPC, checking all VPCs...")
                all_vpcs = ec2.describe_vpcs()
                if all_vpcs["Vpcs"]:
                    vpc_id = all_vpcs["Vpcs"][0]["VpcId"]
                    for key in instance_keys:
                        update_status_func(key, "Using VPC")
                    log_message(f"[{region}] Using VPC {vpc_id}")
                else:
                    for key in instance_keys:
                        update_status_func(key, "ERROR: No VPCs found", is_final=True)
                    return []
            else:
                vpc_id = vpcs["Vpcs"][0]["VpcId"]
                for key in instance_keys:
                    update_status_func(key, "Using default VPC")
                log_message(f"[{region}] Using default VPC {vpc_id}")
            
            # Cache the VPC
            with CACHE_LOCK:
                VPC_CACHE[region] = vpc_id

        # Check subnet cache
        subnet_id = None
        cache_key = f"{region}:{vpc_id}"
        with CACHE_LOCK:
            if cache_key in SUBNET_CACHE:
                subnet_id = SUBNET_CACHE[cache_key]
                for key in instance_keys:
                    update_status_func(key, "Using cached subnet")
        
        if not subnet_id:
            for key in instance_keys:
                update_status_func(key, "Finding subnet")
            subnets = ec2.describe_subnets(
                Filters=[
                    {"Name": "vpc-id", "Values": [vpc_id]},
                    {"Name": "default-for-az", "Values": ["true"]},
                ]
            )
            if not subnets["Subnets"]:
                for key in instance_keys:
                    update_status_func(key, "Finding any subnet")
                all_subnets = ec2.describe_subnets(
                    Filters=[{"Name": "vpc-id", "Values": [vpc_id]}]
                )
                if all_subnets["Subnets"]:
                    subnet_id = all_subnets["Subnets"][0]["SubnetId"]
                    for key in instance_keys:
                        update_status_func(key, "Using subnet")
                else:
                    for key in instance_keys:
                        update_status_func(key, "ERROR: No subnets found", is_final=True)
                    return []
            else:
                subnet_id = subnets["Subnets"][0]["SubnetId"]
                for key in instance_keys:
                    update_status_func(key, "Using default subnet")
            
            # Cache the subnet
            with CACHE_LOCK:
                SUBNET_CACHE[cache_key] = subnet_id

        for key in instance_keys:
            update_status_func(key, "Setting up SG")
        sg_id = create_simple_security_group(ec2, vpc_id)

        for key in instance_keys:
            update_status_func(key, "Finding AMI")
        ami_id = get_latest_ubuntu_ami(region, log_message)
        if not ami_id:
            for key in instance_keys:
                update_status_func(key, "ERROR: No AMI found", is_final=True)
            return []

        region_config = config.region_config(region)
        instance_type = region_config.get("machine_type", "t3.medium")
        with lock:
            for key in instance_keys:
                creation_status[key]["type"] = instance_type

        # Use minimal cloud-init for basic setup
        user_data = generate_minimal_cloud_init(config)

        for key in instance_keys:
            update_status_func(key, "Requesting spot")

        security_groups = [sg_id] + config.security_groups()
        spot_request = {
            "ImageId": ami_id,
            "InstanceType": instance_type,
            "SecurityGroupIds": security_groups,
            "SubnetId": subnet_id,
            "UserData": base64.b64encode(user_data.encode()).decode(),
        }
        if config.ssh_key_name():
            spot_request["KeyName"] = config.ssh_key_name()

        # Add IAM instance profile if configured
        iam_profile = config.iam_instance_profile()
        if iam_profile:
            spot_request["IamInstanceProfile"] = {"Name": iam_profile}

        spot_params = {
            "InstanceCount": count,
            "LaunchSpecification": spot_request,
            "Type": "one-time",
        }
        spot_price = region_config.get("spot_price_limit") or config.spot_price_limit()
        if spot_price:
            spot_params["SpotPrice"] = str(spot_price)

        response = ec2.request_spot_instances(**spot_params)
        spot_request_ids = [
            req["SpotInstanceRequestId"] for req in response["SpotInstanceRequests"]
        ]

        for key in instance_keys:
            update_status_func(key, "WAIT: Launching...")

        instances = []
        for attempt in range(30):
            try:
                spot_response = ec2.describe_spot_instance_requests(
                    SpotInstanceRequestIds=spot_request_ids
                )
                active_requests = [
                    req
                    for req in spot_response["SpotInstanceRequests"]
                    if req["State"] == "active" and "InstanceId" in req
                ]

                if len(active_requests) == count:
                    for key in instance_keys:
                        update_status_func(key, "Fetching details")
                    instance_ids = [req["InstanceId"] for req in active_requests]
                    instance_response = ec2.describe_instances(InstanceIds=instance_ids)

                    instance_idx = 0
                    for reservation in instance_response["Reservations"]:
                        for inst in reservation["Instances"]:
                            instances.append(
                                {
                                    "id": inst["InstanceId"],
                                    "region": region,
                                    "type": inst["InstanceType"],
                                    "state": inst["State"]["Name"],
                                    "public_ip": inst.get("PublicIpAddress", ""),
                                    "private_ip": inst.get("PrivateIpAddress", ""),
                                    "created": datetime.now().isoformat(),
                                }
                            )
                            if instance_idx < len(instance_keys):
                                instance_id = inst["InstanceId"]
                                public_ip = inst.get("PublicIpAddress", "")
                                private_ip = inst.get("PrivateIpAddress", "")
                                
                                # Use public IP if available, otherwise fall back to private IP
                                display_ip = public_ip if public_ip else private_ip
                                
                                # Update the console logger's IP map if available
                                if hasattr(logger, 'console_handler') and display_ip:
                                    logger.console_handler.instance_ip_map[instance_id] = display_ip
                                
                                # Debug: Log what we're sending
                                logger.debug(f"Calling update_status_func with: key={instance_keys[instance_idx]}, id={instance_id}, ip={display_ip}")
                                
                                update_status_func(
                                    instance_keys[instance_idx],
                                    "SUCCESS: Created",
                                    instance_id,
                                    display_ip,
                                    datetime.now().isoformat(),
                                    is_final=False, # Not final until setup is complete
                                )
                                instance_idx += 1

                    if instance_ids:
                        tags = [
                            {"Key": "ManagedBy", "Value": "SpotDeployer"},
                            {"Key": "Name", "Value": f"SpotInstance-{region}"},
                        ]
                        tags.extend(
                            [{"Key": k, "Value": v} for k, v in config.tags().items()]
                        )
                        tags.extend(
                            [
                                {"Key": k, "Value": v}
                                for k, v in region_config.get("tags", {}).items()
                            ]
                        )
                        ec2.create_tags(Resources=instance_ids, Tags=tags)
                    break

                if any(
                    req["State"] in ["failed", "cancelled"]
                    for req in spot_response["SpotInstanceRequests"]
                ):
                    for key in instance_keys:
                        update_status_func(key, "ERROR: Spot failed", is_final=True)
                    break

                for key in instance_keys:
                    update_status_func(key, f"WAIT: Spot wait ({attempt + 1}/30)")
                time.sleep(10)
            except Exception as e:
                if "InvalidSpotInstanceRequestID.NotFound" in str(e):
                    for key in instance_keys:
                        update_status_func(
                            key, "ERROR: Spot Request Expired/Invalid", is_final=True
                        )
                    log_message(
                        f"[{region}] Spot request ID not found. It likely failed immediately. Check AWS console for reason."
                    )
                else:
                    for key in instance_keys:
                        update_status_func(key, f"ERROR: {e}", is_final=True)
                break
        
        # After instances are created, wait for SSH and then perform setup
        for instance in instances:
            ip = instance.get("public_ip")
            if not ip:
                continue

            key = f"{instance['region']}-{instances.index(instance) + 1}"
            update_status_func(key, "WAIT: SSH ready...")
            if wait_for_ssh_only(ip, config.username(), config.private_ssh_key_path()):
                update_status_func(key, "SETUP: SSH ready")
                
                # Now perform the setup for this instance
                update_status_func(key, "SETUP: Uploading files...")
                if upload_files_to_instance(ip, config.username(), config.private_ssh_key_path(), config, logger):
                    update_status_func(key, "SETUP: Enabling services...")
                    if enable_startup_service(ip, config.username(), config.private_ssh_key_path(), logger):
                        update_status_func(key, "SUCCESS: Deployment complete", is_final=True)
                    else:
                        update_status_func(key, "ERROR: Service enablement failed", is_final=True)
                else:
                    update_status_func(key, "ERROR: File upload failed", is_final=True)
            else:
                update_status_func(key, "ERROR: SSH timeout", is_final=True)


        if not instances:
            for key in instance_keys:
                update_status_func(key, "ERROR: Timeout", is_final=True)

        return instances

    except Exception as e:
        for key in instance_keys:
            update_status_func(key, f"ERROR: {e}", is_final=True)
        return []


# =============================================================================
# MAIN COMMANDS
# =============================================================================


def cmd_create(config: SimpleConfig, state: SimpleStateManager) -> None:
    """Create spot instances across configured regions with enhanced real-time progress tracking."""
    if not check_aws_auth():
        return

    # Show helpful info about the deployment process
    console.print("\n[bold cyan]ðŸš€ Starting AWS Spot Instance Deployment[/bold cyan]")
    console.print("\n[bold]Hands-off Deployment Process:[/bold]")
    console.print(
        "1. [yellow]Create Instances[/yellow] - Request spot instances from AWS"
    )
    console.print("2. [blue]Wait for SSH[/blue] - Basic connectivity check")
    console.print("3. [green]Upload Files[/green] - Transfer scripts and configuration")
    console.print("4. [magenta]Enable Service[/magenta] - Set up systemd service")
    console.print("5. [cyan]Disconnect[/cyan] - Let cloud-init complete autonomously")
    console.print(
        "\n[dim]After ~5 minutes, instances will be fully configured and running.[/dim]\n"
    )

    # Setup local logging
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    log_filename = f"spot_creation_{timestamp}.log"
    logger = logging.getLogger("spot_creator")
    logger.setLevel(logging.INFO)

    if not logger.handlers:
        # File handler
        file_handler = logging.FileHandler(log_filename)
        file_handler.setLevel(logging.INFO)
        formatter = logging.Formatter("%(asctime)s - %(threadName)s - %(message)s")
        file_handler.setFormatter(formatter)
        logger.addHandler(file_handler)
        
        # Console handler to capture thread output with instance context
        console_handler = ConsoleLogger(console, {})
        console_formatter = logging.Formatter("%(message)s")
        console_handler.setFormatter(console_formatter)
        logger.addHandler(console_handler)
        
        # Store reference to console handler for updating IP map
        logger.console_handler = console_handler

    rich_status(f"Logging to local file: {log_filename}")

    # Check for SSH key
    private_key_path = config.private_ssh_key_path()
    if private_key_path:
        expanded_path = os.path.expanduser(private_key_path)
        if not os.path.exists(expanded_path):
            rich_error(f"Private SSH key not found at '{private_key_path}'")
            return
    else:
        rich_warning(
            "Private SSH key path is not set in config.yaml. SSH-based operations will fail."
        )

    regions = config.regions()
    if not regions:
        rich_error("No regions configured. Run 'setup' first.")
        return

    region_instance_map = {}
    total_instances_to_create = 0
    for region in regions:
        region_cfg = config.region_config(region)
        count = region_cfg.get("instances_per_region", 1)
        region_instance_map[region] = count
        total_instances_to_create += count

    if total_instances_to_create == 0:
        rich_warning("No instances configured to be created.")
        return

    creation_status = {}
    all_instances = []
    lock = threading.Lock()

    for region, count in region_instance_map.items():
        region_cfg = config.region_config(region)
        instance_type = region_cfg.get("machine_type", "t3.medium")
        for i in range(count):
            key = f"{region}-{i + 1}"
            creation_status[key] = {
                "region": region,
                "instance_id": "pending...",
                "status": "WAIT: Starting...",
                "type": instance_type,
                "public_ip": "pending...",
                "created": "pending...",
            }

    def generate_layout():
        table = Table(
            title=f"Creating {total_instances_to_create} instances",
            show_header=True,
            width=ColumnWidths.get_total_width(),
        )
        table.add_column("Region", style="magenta", width=ColumnWidths.REGION)
        table.add_column("Instance ID", style="cyan", width=ColumnWidths.INSTANCE_ID)
        table.add_column("Status", style="yellow", width=ColumnWidths.STATUS)
        table.add_column("Type", style="green", width=ColumnWidths.TYPE)
        table.add_column("Public IP", style="blue", width=ColumnWidths.PUBLIC_IP)
        table.add_column("Created", style="dim", width=ColumnWidths.CREATED)

        sorted_items = sorted(creation_status.items(), key=lambda x: x[0])
        for key, item in sorted_items:
            status = item["status"]
            if "SUCCESS" in status:
                status_style = f"[bold green]{status}[/bold green]"
            elif "ERROR" in status:
                status_style = f"[bold red]{status}[/bold red]"
            else:
                status_style = status
            table.add_row(
                item["region"],
                item["instance_id"],
                status_style,
                item["type"],
                item["public_ip"],
                item["created"],
            )
        
        try:
            with open(log_filename, 'r') as f:
                log_content = "\n".join(f.readlines()[-10:])
        except (FileNotFoundError, IOError):
            log_content = "Waiting for log entries..."
        
        log_panel = Panel(log_content, title="On-Screen Log", border_style="blue", height=12)
        
        layout = Layout()
        layout.split_column(Layout(table), Layout(log_panel))
        return layout

    def update_status(key, status, instance_id=None, ip=None, created=None, is_final=False):
        with lock:
            if key in creation_status:
                creation_status[key]["status"] = status
                if instance_id:
                    creation_status[key]["instance_id"] = instance_id
                if ip:
                    creation_status[key]["public_ip"] = ip
                if created:
                    creation_status[key]["created"] = created
            
            log_ip = ip if ip else "N/A"
            log_id = instance_id if instance_id else key
            logger.info(f"[{log_id} @ {log_ip}] {status}")

    with Live(generate_layout(), refresh_per_second=4, console=console) as live:
        
        def create_region_instances(region, count):
            try:
                instances = create_instances_in_region_with_table(
                    config, region, count, creation_status, lock, logger, update_status
                )
                with lock:
                    all_instances.extend(instances)
            except Exception as e:
                logger.error(f"Error in create_region_instances for {region}: {e}")

        with ThreadPoolExecutor(max_workers=len(regions), thread_name_prefix="Create") as executor:
            futures = [executor.submit(create_region_instances, r, c) for r, c in region_instance_map.items()]
            while any(f.running() for f in futures):
                live.update(generate_layout())
                time.sleep(0.25)
        
        live.update(generate_layout()) # Final update after creation phase

        if all_instances:
            rich_status("All instances created. Starting post-creation setup...")
            live.update(generate_layout())
            
            post_creation_setup(all_instances, config, update_status, logger)
            
            # Keep the live display running during setup
            # This part is tricky as post_creation_setup is blocking with its own threads.
            # A better approach would be a fully event-driven UI, but for now, we'll just refresh after it's done.
            live.update(generate_layout())

    rich_success(f"Deployment process complete for {len(all_instances)} instances.")
    state.save_instances(all_instances)
    cmd_list(state)


def cmd_setup(config: SimpleConfig) -> None:
    """Guide user through creating a default config.yaml."""
    if os.path.exists(config.config_file):
        rich_warning(f"'{config.config_file}' already exists.")
        if input("Overwrite? (y/n): ").lower() != "y":
            return

    # Default configuration
    default_config = {
        "aws": {
            "total_instances": 3,
            "username": "ubuntu",
            "ssh_key_name": "your-ssh-key-name",
            "public_ssh_key_path": "~/.ssh/id_rsa.pub",
            "private_ssh_key_path": "~/.ssh/id_rsa",
            "files_directory": "files",
            "scripts_directory": "instance/scripts",
            "cloud_init_template": "instance/cloud-init/init-vm-template.yml",
            "startup_script": "instance/scripts/startup.py",
            "instance_storage_gb": 50,
            "tags": {"Project": "SpotDeployer"},
        },
        "regions": [
            {"us-west-2": {"image": "auto", "machine_type": "t3.medium"}},
            {"us-east-1": {"image": "auto", "machine_type": "t3.medium"}},
            {"eu-west-1": {"image": "auto", "machine_type": "t3.medium"}},
        ],
    }

    try:
        with open(config.config_file, "w") as f:
            yaml.dump(default_config, f, default_flow_style=False, sort_keys=False)
        rich_success(f"Created default config: {config.config_file}")
        console.print(
        "\n[bold yellow]ACTION REQUIRED:[/bold yellow] Please edit this file with your details."
    )
    except Exception as e:
        rich_error(f"Failed to create config file: {e}")


def cmd_list(state: SimpleStateManager) -> None:
    """List running instances from state file."""
    instances = state.load_instances()
    if not instances:
        rich_print("No instances found in state file.", style="yellow")
        return

    if RICH_AVAILABLE and console:
        table = Table(title="Running Spot Instances")
        table.add_column("Region", style="magenta")
        table.add_column("Instance ID", style="cyan")
        table.add_column("Type", style="green")
        table.add_column("Public IP", style="blue")
        table.add_column("State", style="yellow")
        table.add_column("Created", style="dim")

        for inst in sorted(instances, key=lambda i: i.get("region", "")):
            table.add_row(
                inst.get("region", "N/A"),
                inst.get("id", "N/A"),
                inst.get("type", "N/A"),
                inst.get("public_ip", "N/A"),
                inst.get("state", "N/A"),
                inst.get("created", "N/A"),
            )
        console.print(table)
    else:
        for inst in instances:
            print(
                f"{inst.get('region')} | {inst.get('id')} | {inst.get('public_ip')} | {inst.get('state')}"
            )


def cmd_destroy(config: SimpleConfig, state: SimpleStateManager) -> None:
    """Terminate running instances and clean up resources."""
    if not check_aws_auth():
        return

    instances = state.load_instances()
    if not instances:
        rich_warning("No instances to destroy.")
        return

    rich_warning("This will terminate all managed instances and delete the associated security group.")
    if input("Are you sure? (y/n): ").lower() != "y":
        return

    # Group instances by region
    region_map = {}
    for inst in instances:
        region = inst.get("region")
        if region not in region_map:
            region_map[region] = []
        region_map[region].append(inst["id"])

    # Terminate instances and security groups in parallel
    def terminate_in_region(region, instance_ids):
        try:
            rich_status(f"Terminating {len(instance_ids)} instances in {region}...")
            ec2 = boto3.client("ec2", region_name=region)
            ec2.terminate_instances(InstanceIds=instance_ids)
            rich_success(f"Termination request sent for instances in {region}.")

            # Wait for instances to terminate before deleting security group
            waiter = ec2.get_waiter('instance_terminated')
            waiter.wait(InstanceIds=instance_ids)
            rich_success(f"Instances in {region} terminated.")

            # Delete the security group
            try:
                rich_status(f"Deleting security group in {region}...")
                ec2.delete_security_group(GroupName='spot-deployer-sg')
                rich_success(f"Security group 'spot-deployer-sg' deleted in {region}.")
            except ec2.exceptions.ClientError as e:
                if "does not exist" in str(e):
                    rich_warning(f"Security group 'spot-deployer-sg' not found in {region}.")
                else:
                    rich_error(f"Failed to delete security group in {region}: {e}")
            
            return region
        except Exception as e:
            rich_error(f"Failed to terminate instances or security group in {region}: {e}")
            return None

    with ThreadPoolExecutor(max_workers=len(region_map)) as executor:
        futures = [
            executor.submit(terminate_in_region, r, ids)
            for r, ids in region_map.items()
        ]
        for future in futures:
            terminated_region = future.result()
            if terminated_region:
                state.remove_instances_by_region(terminated_region)

    rich_success("All managed instances have been scheduled for termination and security groups are being cleaned up.")


def cmd_help() -> None:
    """Display a Rich help panel."""
    if RICH_AVAILABLE and console:
        help_text = """
[bold]AWS Spot Instance Deployer[/bold]

[bold]Usage:[/bold]
  [cyan]./deploy_spot.py [command][/cyan]

[bold]Commands:[/bold]
  [green]setup[/green]      - Create a default 'config.yaml' file.
  [green]create[/green]     - Create and deploy spot instances based on 'config.yaml'.
  [green]list[/green]       - List all currently managed instances from 'instances.json'.
  [green]destroy[/green]    - Terminate all managed instances and clean up resources.
  [green]help[/green]       - Show this help message.
"""
        console.print(Panel(help_text, title="Help", border_style="blue"))
    else:
        print("Usage: ./deploy_spot.py [setup|create|list|destroy|help]")


# =============================================================================
# MAIN EXECUTION
# =============================================================================


def main() -> None:
    """Main entry point."""
    if len(sys.argv) < 2:
        cmd_help()
        return

    command = sys.argv[1]
    config = SimpleConfig()
    state = SimpleStateManager()

    if command == "setup":
        cmd_setup(config)
    elif command == "create":
        cmd_create(config, state)
    elif command == "list":
        cmd_list(state)
    elif command == "destroy":
        cmd_destroy(config, state)
    elif command == "help":
        cmd_help()
    else:
        rich_error(f"Unknown command: {command}")
        cmd_help()


if __name__ == "__main__":
    main()
